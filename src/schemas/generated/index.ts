/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */

export type paths = Record<string, never>;
export type webhooks = Record<string, never>;
export interface components {
    schemas: {
        /** @description AIHelper configuration - flexible schema allowing any properties for future extensibility */
        AIHelper: Record<string, never>;
        AudioMediaConfig: {
            /**
             * @description Reference to one of the preset of the platform. One is always present and it's called 'default'
             * @default default
             */
            presetId: string;
        } & components["schemas"]["BaseAudioMediaConfig"];
        AudioMediaConfigPreset: WithRequired<components["schemas"]["BaseAudioMediaConfig"], "llm" | "stt" | "tts" | "vad" | "allowInterruptionsOnStart" | "allowInterruptions" | "enableRecording" | "userInteractionTimeout" | "preemptiveGeneration">;
        BaseAudioMediaConfig: {
            llm?: components["schemas"]["LLMConfig"];
            stt?: components["schemas"]["STTConfig"];
            tts?: components["schemas"]["TTSConfig"];
            vad?: components["schemas"]["VADConfig"];
            /** @description Controls if user can interrupt AI when playing the first message */
            allowInterruptionsOnStart?: boolean;
            /** @description Controls if user can interrupt AI in messages after the first message played */
            allowInterruptions?: boolean;
            /** @description Contains the configuration for enabling courtesy messages. If not set, courtesy messages are disabled */
            courtesyMessageConfig?: components["schemas"]["CourtesyMessageConfig"] | null;
            /**
             * @description Enables recording of the conversation
             * @default false
             */
            enableRecording: boolean;
            /**
             * @description Maximum waiting time (in seconds) for user response before triggering a no_utterance event.
             * @default 20
             */
            userInteractionTimeout: number;
            /**
             * @description If true, the LLM can start generating responses before the user finishes speaking.
             * @default false
             */
            preemptiveGeneration: boolean;
        };
        BaseSTTConfig: {
            provider: string;
            /**
             * @description Time to wait before issuing an unclear utterance message
             * @default 2.5
             */
            recognitionTimeout: number;
            /**
             * @description Enables or disables streaming STT mode.
             * @default false
             */
            streaming: boolean;
            /**
             * @description Enables interim (partial) recognition results during streaming.
             * @default false
             */
            interimResults: boolean;
            /**
             * @description Optional vocabulary hints to improve speech recognition accuracy.
             * @default []
             */
            hints: string[];
            /**
             * @description Weight multiplier applied to hints.
             * @default 1
             */
            hintsBoost: number;
            /**
             * @description Minimum delay that is waited after user ends to speak and turn detection thinks the turn is ended
             * @default 1.5
             */
            minEndpointingDelay: number;
            /**
             * @description Maximum delay that is waited after user ends to speak and turn detection thinks the turn is NOT yet ended
             * @default 3
             */
            maxEndpointingDelay: number;
            /**
             * @description User must speak at least this duration to interrupt the bot speaking
             * @default 0.7
             */
            minInterruptionDuration: number;
        };
        BaseTTSConfig: {
            provider: string;
            /** @description (Template of) Voice ID according to provider specifications */
            voice: string;
            /** @default 1 */
            speed: number;
        };
        Checkpoint: {
            _id: string;
            /** @description Name of the Checkpoint */
            name: string;
            /** @description The LLM prompt used to identify the Checkpoint */
            prompt: string;
            /**
             * @description The flag that indicates if the current checkpoint is mandatory
             * @default false
             */
            required: boolean;
        };
        ClosureConfig: {
            /**
             * @description If it's false a conversation is closed when the contact that originated it terminates. If it's true, conversationTimeLimit and customHandler will determinate the behaviour at the end of a contact
             * @default false
             */
            multiContact: boolean;
            /** @description Defines the maximum absolute duration of the conversation in seconds. Mandatory if multiContact is true */
            conversationTimeLimit?: number;
            /** @description Url that will respond true/false (close/don't close) when a contact terminate. Mandatory if multiContact is true */
            customHandler?: string;
        } & unknown;
        /** @description It's the main record that declares the existance of a Conversational Flow within a campaign */
        ConversationalFlow: {
            /** @description MongoDB ID of the conversational flow */
            _id: string;
            /** @description Name of the Conversational Flow */
            name: string;
            /** @description Reference to the Campaign owning the Conversational Flow */
            campaignId: string;
            schemaVersion: components["schemas"]["SchemaVersionString"];
            /** @description The user that created the Conversational Flow or updated it's name */
            updatedBy: string;
            /**
             * Format: date-time
             * @description ISO Timestamp when the last insert/update operation has been done
             */
            updatedAt: string;
        };
        ConversationalFlowTask: {
            _id: string;
            /**
             * @description The type of the current task: AI only (AIO), human (HUM) or AI supervised (AIS)
             * @enum {string}
             */
            type: "AIO" | "AIS" | "HUM";
            /** @description The prompt used by the AI in order to move to the current task from a linked one */
            description: string;
            /** @description The prompt used by the AI to describe the current task */
            prompt: string;
            transitionParameters: components["schemas"]["TransitionParameter"][];
            aiHelpers?: components["schemas"]["AIHelper"][];
            /** @description The list of the available channel. In case of null all channels are enabled */
            channels?: ("phone" | "whatsapp" | "sms" | "mail" | "chat")[] | null;
            /** @description The list of MCP Servers available for the current task */
            mcpToolSelection?: components["schemas"]["MCPToolSelection"][];
            /** @description A specific closure config to be used in the specific task. This configuration overrides the one set on the conversational flow. */
            closureConfig: components["schemas"]["ClosureConfig"];
            /** @description The list of selected checkpoint for the current task */
            enabledCheckpoints: components["schemas"]["Checkpoint"][];
            /** @description Task ids connected to this one */
            connectedTasks?: string[];
        };
        ConversationalFlowTaskAIO: {
            /** @description Automatically hide transcriptions to human */
            hideTranscriptionToHuman?: boolean;
        } & components["schemas"]["ConversationalFlowTask"];
        ConversationalFlowTaskAIS: components["schemas"]["ConversationalFlowTaskHUM"];
        ConversationalFlowTaskHUM: {
            routingParameters: components["schemas"]["RoutingParameters"];
        } & components["schemas"]["ConversationalFlowTask"];
        /** @description It's a version of a conversational flow defined in ConversationalFlow with all the settings needed to render in the UI and also to have a working FSM */
        ConversationalFlowVersion: {
            /** @description MongoDB ID of the conversational flow version */
            _id?: string;
            schemaVersion?: components["schemas"]["SchemaVersionString"];
            /** @description Reference to the Conversational Flow */
            conversationalFlowId?: string;
            /** @description It's the main prompt that defines the rules of the conversation. It's rendered in every prompt sent to LLM. The template format is the one used by n8n tournament rendering engine. */
            globalPrompt?: string;
            channels?: ("phone" | "whatsapp" | "sms" | "mail" | "chat")[];
            mandatoryChannels?: ("phone" | "whatsapp" | "sms" | "mail" | "chat")[];
            closureConfig?: components["schemas"]["ClosureConfig"];
            mediaConfig?: components["schemas"]["MediaConfig"];
            languageDetection?: components["schemas"]["LanguageDetectionConfig"];
            /** @description Default language when a new conversation starts */
            defaultLanguage?: components["schemas"]["LanguageCode"];
            /** @description Languages supported by the conversational flow */
            supportedLanguages?: components["schemas"]["LanguageCode"][];
            /** @description Language used to build the system prompts. The available ones are: it-IT, en-US, es-ES. In case defaultLanguage contains a different language value, the default is en-US. */
            systemPromptsLanguage?: components["schemas"]["LanguageCode"];
            /** @description The current version of the system api */
            apiVersion?: string;
            variables?: components["schemas"]["Variable"][];
            /** @description The object containing the UI metadata */
            uiMetadata?: Record<string, never>;
            /** @description The list of MCP Servers available for the current conversational flow */
            mcpServers?: components["schemas"]["MCPServer"][];
            aiHelpers?: components["schemas"]["AIHelper"][];
            tasks?: components["schemas"]["ConversationalFlowTask"][];
            /** @description Id of the first task to be executed in the flow */
            firstTask?: string;
            /** @description The list of defined checkpoint for the current conversational flow */
            checkpoints?: components["schemas"]["Checkpoint"][];
            /** @description The list of available reasons of contact */
            reasonsOfContact?: {
                /** @description Declared reason of contact */
                name: string;
                /** @description The prompt used by the AI in order to choose the reason of contact */
                prompt: string;
            }[];
            /** @description The list of results */
            results?: {
                /** @description Declared result */
                name: string;
                /** @description The prompt used by the AI in order to choose the result */
                prompt: string;
                resultTypes: ("CL" | "UNC" | "UC" | "Y" | "UPS")[];
            }[];
            /** @description The user that created the current flow version */
            createdBy?: string;
            /**
             * Format: date-time
             * @description ISO Timestamp when the current conversational flow version has been created
             */
            createdAt?: string;
            /**
             * @description If draft is true all other fields are not required
             * @default false
             */
            draft: boolean;
        } & unknown;
        CourtesyMessageConfig: {
            /** @enum {string} */
            provider: "groq" | "random";
            /** @description Time interval (seconds) before playing the courtesy message */
            timeout: number;
            /**
             * @description Time interval (seconds) to wait before playing the AI message after a courtesy message
             * @default 1
             */
            silenceAfterMessage: number;
            providerParams: components["schemas"]["CourtesyMessageGroqParams"] | components["schemas"]["CourtesyMessageRandomParams"];
        };
        CourtesyMessageGroqParams: {
            /**
             * @description Number of previous messages to include in the courtesy message prompt context
             * @default 5
             */
            historyMessages: number;
            /**
             * @description Prompt used to generate the courtesy message
             * @default [Prompt defined by the system]
             */
            prompt: string;
            /**
             * @description Creativity level of the LLM when generating the courtesy message
             * @default 0.2
             */
            temperature: number;
            /**
             * @description Max number of tokens for the generated courtesy message
             * @default 30
             */
            maxCompletionTokens: number;
            /**
             * @description Nucleus sampling parameter for the generated courtesy message
             * @default 0.8
             */
            topP: number;
            /**
             * @description AI Model used for courtesy message generation. Any model supported by groq is accepted.
             * @default meta-llama/llama-4-scout-17b-16e-instruct
             * @enum {string}
             */
            model: "meta-llama/llama-4-scout-17b-16e-instruct";
        };
        CourtesyMessageRandomParams: {
            messages?: components["schemas"]["LocalizedText"][];
        };
        LLMConfig: {
            /** @enum {string} */
            provider?: "openai" | "azure" | "google" | "local" | "groq";
            /** @description Reference to one the models provided by SmileCX */
            model?: string;
            /** @description Defines the "creativity" of the AI Model */
            temperature?: number;
        };
        /**
         * @description Array of languages in BCP 47 format (ISO 639-1 + ISO 3166-1).
         * @example it-IT or en-US
         */
        LanguageCode: string;
        LanguageDetectionConfig: {
            /**
             * @description Enables automatic language detection from user input.
             * @default false
             */
            enableLanguageDetection: boolean;
            /**
             * @description Minimum number of words required to attempt language detection.
             * @default 2
             */
            minWordsForLanguageDetection: number;
            /**
             * @description Algorithm used for language detection. Supported: "fasttext", "lingua".
             * @default fasttext
             * @enum {string}
             */
            languageDetector: "fasttext" | "lingua";
        };
        LanguageSTTConfig: {
            /** @description Language in ISO 639-1 - two chars (en, it, ..) */
            language?: string;
            config?: components["schemas"]["BaseSTTConfig"];
        };
        LanguageTTSConfig: {
            /** @description Language in ISO 639-1 - two chars (en, it, ..) */
            language?: string;
            config?: components["schemas"]["BaseTTSConfig"];
        };
        LocalizedText: {
            /** @description Language in ISO 639-1 - two chars (en, it, ..) */
            language: string;
            text: string;
        };
        MCPServer: {
            /** @description Name of the MCPServer */
            name: string;
            /** @description The url of the current MCPServer */
            url: string;
            /** @description The list of tools selected inside the specific MCP Server */
            includedTools: {
                /** @description Name of the specific tool */
                toolName?: string;
                /** @description The description of the specific tool for selecting in the UI */
                uiToolDescription?: string;
            }[];
        };
        MCPToolParameter: {
            /** @description The name of the parameter */
            parameterName: string;
            /**
             * @description The strategy used for assigning the value
             * @enum {string}
             */
            assignmentStrategy: "variable" | "fixed" | "prompt";
            /** @description This depends on assignmentStrategy, it could be : <br/>- a variable id <br/>- a fixed value <br/>- a prompt for helping the ai on calculate the real value that should be passed */
            assignmentValue: string;
        };
        MCPToolParametersMap: {
            /** @description The name of the tool in the MCP Server */
            toolName: string;
            /** @description The list of parameters for the tools selected */
            toolParameters?: components["schemas"]["MCPToolParameter"][];
        };
        MCPToolSelection: {
            /** @description The MCP Server name from the list of MCP Servers supplied by the conversational flow */
            mcpServerName: string;
            /** @description The list of tools selected for this MCP Server */
            selectedTools: components["schemas"]["MCPToolParametersMap"][];
        };
        MediaConfig: {
            audio: components["schemas"]["AudioMediaConfig"];
            text: components["schemas"]["TextMediaConfig"];
        };
        RoutingParameters: {
            /** @description Time to wait before considering the routing request failed (no answer by agents) */
            timeout: number;
            /** @description Skills required by the routing request */
            agentSkills?: string[];
            /** @description Optional skills required by the routing request */
            agentOptionalSkills?: string[];
            /** @description Specific agents required by the routing request */
            agentIds?: string[];
            /** @description Url to specific music to play during waiting */
            waitingMusic?: string;
            /** @description Interval between waiting messages */
            waitingMusicDuration?: number;
            waitingMessagesConfiguration?: components["schemas"]["WaitingMessagesConfiguration"];
        };
        STTConfig: {
            default: components["schemas"]["BaseSTTConfig"];
            fallback: components["schemas"]["BaseSTTConfig"];
            languageCustomConfig?: components["schemas"]["LanguageSTTConfig"][] | null;
        };
        /**
         * @description Version of the object schema to handle future schema updates or migrations
         * @example 1.0.0
         */
        SchemaVersionString: string;
        TTSConfig: {
            default: components["schemas"]["BaseTTSConfig"];
            fallback: components["schemas"]["BaseTTSConfig"];
            languageCustomConfig?: components["schemas"]["LanguageTTSConfig"][] | null;
        };
        TextMediaConfig: {
            llm?: components["schemas"]["LLMConfig"];
            /** @description Contains the configuration for enabling courtesy messages. If not set, courtesy messages are disabled */
            courtesyMessageConfig?: components["schemas"]["CourtesyMessageConfig"] | null;
            /** @description Maximum waiting time (in seconds) for user response before triggering a no_utterance event. (default: never) */
            userInteractionTimeout?: number | null;
        };
        TransitionParameter: {
            /** @description The id of the variable selected from the available variables for the conversational flow */
            variableId: string;
            required: boolean;
        };
        VADConfig: {
            /**
             * @description Threshold to consider a frame as speech.
             * @default 0.5
             */
            activationThreshold: number;
            /**
             * @description Maximum duration of speech to keep in the buffer (in seconds).
             * @default 60
             */
            maxBufferedSpeech: number;
            /**
             * @description At the end of each speech, wait this duration before ending the speech.
             * @default 0.8
             */
            minSilenceDuration: number;
            /**
             * @description Minimum duration of speech to start a new speech chunk.
             * @default 0.08
             */
            minSpeechDuration: number;
            /**
             * @description Duration of padding to add to the beginning of each speech chunk.
             * @default 0.5
             */
            prefixPaddingDuration: number;
        };
        Variable: {
            _id: string;
            /** @description Variable name */
            name: string;
            /**
             * @description Variable type
             * @enum {string}
             */
            type: "string" | "number" | "boolean" | "enum" | "date" | "phone" | "custom";
            enumValues?: string[];
            /** @description The prompt used by the AI in order to identify the variable */
            prompt?: string;
        };
        WaitingMessagesConfiguration: {
            /**
             * @description Strategy to generate waiting messages
             * @enum {string}
             */
            generationStrategy: "fixed" | "prompt";
            /** @description Prompt for generating waiting messages */
            prompt?: string;
            messagesList?: components["schemas"]["LocalizedText"][];
        };
    };
    responses: never;
    parameters: never;
    requestBodies: never;
    headers: never;
    pathItems: never;
}
export type $defs = Record<string, never>;
type WithRequired<T, K extends keyof T> = T & {
    [P in K]-?: T[P];
};
export type operations = Record<string, never>;
